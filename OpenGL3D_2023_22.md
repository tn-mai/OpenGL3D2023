[OpenGL 3D 2023 第10回]

# マイクロファセットBRDF

## 習得目標

* 
* 
* 
* 

[ ] 物理ベースレンダリング(スペキュラ+フレネル)
[ ] ノーマルマッピング
[ ] DDSファイルを読み込めるようにする
[ ] アンビエントオクルージョン
[ ] キューブマップ(環境マップ？)
[ ] ウェイポイント
[ ] 「ジュース」について(画面を揺らす、派手な爆発と効果音)

[ ] パースペクティブ・デプスシャドウマップ
[ ] レイヤードレンダーターゲットとジオメトリシェーダによるポイントライト・デプスシャドウマップ

## 1. マイクロファセットBRDF

### 1.1 双方向反射率分布関数(BRDF)

現在のライティングでは拡散反射だけを処理しています。より現実的なライティングを行うには「鏡面反射(きょうめんはんしゃ)」と呼ばれる成分も計算する必要があります。

2024年現在、拡散反射と鏡面反射の計算には「マイクロファセットBRDF(ビーアールディーエフ)」と呼ばれるライティング技法が使われています。

「マイクロファセット」は「微小平面」という意味で、「物体表面を目に見えないほど微小な平面の集合として考える」ライティング技法のことです。

<p align="center">
<img src="images/22_microfacet_model.png" width="45%" /><br>
[拡大図に見える小さな平面ひとつひとつがマイクロファセット]
</p>

BRDFは「双方向反射率分布関数`Bidirectional Reflectance Distribution Function`」の略称で、「ある方向からの入射光が、ある方向に出射する比率」を表します。

「双方向」という名称は、「入射ベクトルと出射ベクトルを入れ替えても結果が変わらない」ことから来ています。

この定義を満たす関数はすべてBRDFと呼ばれます。そのため、エンジンやライブラリによって計算方法の異なるBRDFが使われています。今回は`Unreal Engine`で採用されている計算方法をベースに作成していきます。

>`Unreal Engine`のBRDFを選んだのは、品質と効率のバランスが取れているためです。
>
>cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf

`Unreal Engine`のBRDFは、以下の3つのパラメータを持ちます。

>* ベースカラー(基本となるRGBカラー)
>* メタリック(金属なら`1`、非金属なら`0`)
>* ラフネス(物体表面の粗さを`0.0`～`1.0`で表す)

BRDFはこれらのパラメータを用いて、拡散反射と鏡面反射の2つのBRDFを組み合わせて作成されます。また、一般に入射ベクトルには「光線(ライト)ベクトル」、出射ベクトルには「視線(カメラ)ベクトル」が使われます。

$$
\begin{aligned}
L &= 光線(ライト)ベクトル \\
V &= 視線(カメラ)ベクトル \\
N &= 法線ベクトル \\
\\
総反射率 &= 拡散反射BRDF * (1 - メタリック) + 鏡面反射BRDF \\
\\
拡散反射BRDF &= \dfrac{ベースカラー}{\pi} \\
\\
鏡面反射BRDF &= \dfrac{D * G * F}{4(N \cdot L)(N \cdot V)} \\
\end{aligned}
$$

ここで`D`は「法線分布項」、`G`は「幾何遮蔽項」、`F`は「フレネル項」を表します。`cosθi`は入射ベクトルと法線ベクトルの内積、`cosθo`は出射ベクトル(視線ベクトル)と法線ベクトルの内積です。

* 法線分布項: 「物体表面の凹凸」と「見る角度」によって、面の法線に見え方が変化する現象を再現する。
* 幾何減衰項: 物体表面の凹凸によって、表面の一部が隠れて暗くなる現象を再現する。
* フレネル項: 「水面をナナメに見たときに空の色が見える」という現象を再現する。

これらの3項目は次ように計算します。

$$
\begin{aligned}
H &= normalize(L + N) \\
\\
D &= \dfrac{ラフネス^4}{\pi * ((N \cdot H)^2 * (ラフネス^4 - 1) + 1)^2} \\
\\
k &= \dfrac{(ラフネス + 1)^2}{8} \\
G &= \dfrac{N \cdot L}{(N \cdot L)(1 - k) + k} * \dfrac{N \cdot V}{(N \cdot V)(1 - k) + k} \\
\\
F0 &= 角度0°のときのフレネル値 \\
F &= F0 + (1 - F0)(1 - L \cdot H)^5 \\
\end{aligned}
$$

本テキストでは、この式をそのまま実装していきます。各式の意味については、実装する時に個別に説明します。

### 1.2 法線分布項

表面が十分になめらかな物体では、多くの微小面の法線は表面法線に一致します。しかし、表面が粗い物体の場合、微小面はさまざまな方向を向いていると考えられます(だからザラザラに見える)。

<p align="center">
<img src="images/22_microfacet_roughness.png" width="66%" />
</p>

法線分布項(`Normal Distribution Function`、または`Microfacet Distribution Function`)は、 このような微小面の状態を考慮して、視点から見えるすべてのマイクロファセット法線の平均値を算出する関数です。

法線分布項を表す関数はいくつか考案されていますが、`Unreal Engine`では2007年に`Walter`氏が考案した、GGX(ジージーエックス、`ground grass unknown`)という関数が使われています。GGX関数は次のように定義されます。

$$
\begin{aligned}
H &= (L + N) * 0.5 \\
D &= \dfrac{ラフネス^4}{\pi * ((N \cdot H)^2 * (ラフネス^4 - 1) + 1)^2}
\end{aligned}
$$

`H`は「ハーフベクトル」と呼ばれ、「光線(入射)ベクトルと視線ベクトルの中間を指すベクトル」になります。物理的にはハーフベクトルは「入射光の鏡面反射量が最も多くなる微小面の向き」を意味します。

<p align="center">
<img src="images/22_half_vector.png" width="50%" /><br>
[L=光線ベクトル V=視線ベクトル H=ハーフベクトル]
</p>

`N・H`は「表面法線の向きがハーフベクトルと近いほど、光線を視線方向に反射する微小平面が多くなる」ことを表します。

ラフネスは「物体表面の粗さ」を表すパラメータなのでした。ラフネスが0に近いほど表面がなめらかに、1に近いほど表面が粗くなります。GGXにおけるラフネスは「`N・H`の無視されやすさ」として機能します。

表面が粗いということは微小平面の向きもバラバラなので、ハーフベクトル方向を向いている微小平面が少なくなります。逆になめらかな場合、`N・H`はそのままハーフベクトル方向を向く微小平面の比率になります。

乗数やその他のパラメータ(`-1`や`+`のこと)は、`Unreal Engine`を使うアーティストがラフネスを直感的に操作できるようにと、試行錯誤によって決められた値です。

そ1967年およびれでは、シェーダにGGX関数を定義しましょう。`standard.frag`を開き、ユニフォーム変数の定義の下に`NormalDistributionGGX`(ノーマル・ディストリビューション・ジージーエックス、「GGXによる法線分布」という意味)という名前の関数を追加してください。

```diff
   vec4 directionAndConeAngle[16]; // 向き, 照射角度
 };
 layout(location=110) uniform int lightCount;
 layout(location=111) uniform Light pointLight;
+
+/**
+* 法線分布項
+*/
+float NormalDistributionGGX(vec3 N, vec3 H, float roughness)
+{
+  // 光線を視線方向に反射する微小平面の比率を求める
+  float NdotH = max(dot(N, H), 0);
+  float NdotH2 = NdotH * NdotH;
+
+  // dot(N, H)が影響する比率を求める
+  float r2 = roughness * roughness;
+  float r4 = r2 * r2;
+  float denom = (NdotH2 * (r4 - 1.0) + 1.0);
+  denom = 3.14159265 * denom * denom;
+
+  return r4 / denom;
+}

+/**
+* エントリーポイント
+*/
 void main()
 {
   vec4 c = texture(texColor, inTexcoord);
```

これで法線分布項は完成です。

>`denom`(デノム)は`denominator`(デノミネータ、「分母」という意味)の短縮形です。

### 1.3 幾何減衰項

表面が粗い物体には、目に見えないほど小さな凸凹がたくさん存在します。これらの凸凹によって、ある微小平面に届くはずの光が別の微小平面によって遮られたり、視線の先にある微小平面が奥にある微小平面に隠されるという現象が発生します。

<p align="center">
<img src="images/22_microfacet_geometric_attenuation.png" width="50%" /><br>
[左:視線が他の微小平面に遮られる 右:光線が他の微小平面に遮られる]
</p>

幾何減衰項(きかげんすいこう、`Geometric Attenuation Factor`または`Masking-Shadowing Function`)は、 このような微小面の状態を考慮して、光線が視点に到達する比率を算出する関数です。

`Unreal Engine`では、Smith(スミス)氏が1969年に考案した技法をSchlick(シュリック)氏が改良した式をベースにして、`Unreal Engine`独自の改良を加えたバージョンが使われています。これは次の式になります。

$$
\begin{aligned}
k &= \dfrac{(ラフネス + 1)^2}{8} \\
G0(x) &= \dfrac{N \cdot x}{(N \cdot x)(1 - k) + k} \\
G &= G0(L)G0(V) \\
\end{aligned}
$$

`k`は「凹凸の度合い」を表すパラメータです。`G0`(ジーゼロ)関数は、入射ベクトル(または視線ベクトル)に対する微小平面の見えやすさを計算します。

入射ベクトルが法線ベクトルと直角に近い場合、光が物体表面をかすめるように通過するので、わずかな凹凸でも光が遮られる確率が高くなります。逆に垂直に近い場合はほとんど遮られません。

また、`k`が小さい場合は物体表面の凹凸が大きいことを意味します。この場合、わずかな傾きであっても光が遮られる確率が高くなります。

ある微小平面について、入射光が視線に到達しない主な原因は以下の2つが考えられます。

>* 他の微小平面に遮られて、入射光が目的の微小平面まで届かない(シャドウイング)。
>* 他の微小平面に遮られて、視点から目的の微小平面が見えない(マスキング)。

そこで、先の式では入射ベクトルと視線ベクトルのそれぞれについて、`G'`関数を使って遮蔽率を求めます。次に、これら2つの値を乗算して「入射光が視点に到達する比率」を算出します。

入射ベクトルと視線ベクトルの両方に同じ式を使うことで、BRDFの重要な性質である「双方向性」を満たすようになっています。

それでは幾何減衰項を求める関数を定義しましょう。`NormalDistributionGGX`関数の定義の下に、`GeometricAttenuationSchlick`(ジオメトリック・アテニュエーション・シュリック、「シュリックの幾何減衰」という意味)という名前の関数を追加してください。

```diff
   denom = 3.14159265 * denom * denom;

   return r4 / denom;
 }
+
+/**
+* 幾何減衰項
+*/
+float GeometricAttenuationSchlick(float NdotL, float NdotV, float roughness)
+{
+  float k = (roughness + 1) * (roughness + 1) * 0.125;
+
+  // 光源方向から見た幾何学的減衰項を計算
+  float g0 = NdotL / (NdotL * (1 - k) + k);
+
+  // 視点方向から見た幾何学的減衰項を計算
+  float g1 = NdotV / (NdotV * (1 - k) + k);
+
+  return g0 * g1;
+}

 /**
 * エントリーポイント
 */
 void main()
```

`N・L`と`N・V`はBRDFの他の部分でも使うので、関数の外で計算して引数として受け取る形にしています。

これで、幾何減衰項は完成です。

### 1.4 フレネル項

光が屈折率の異なる物質の境界(「界面(かいめん)」といいます)に入射すると、光の一部が反射され、残りは透過します。この反射と透過の比率は「フレネル方程式」によって表せることが分かっています。

<p align="center">
<img src="images/shana-van-roosbroek-czaKJrW6JVk-unsplash.jpg" width="33%" /><br>
Photo by Shana Van Roosbroek on https://unsplash.com/@shanavaro
</p>

流れの静かな川を見ることを考えてみましょう。水面を真上から見ると、水底まで見通すことができます。そこから、徐々に角度を付けていくと、少しずつ空の色が写り込んできます。

やがて水面をかすめるような角度になると、見えるのは空の色ばかり。水底どころか水中自体がほとんど見えません。「フレネル方程式」は、このような「見る角度によって反射率が異なる」という光のふるまいを表します。

フレネル方程式は水と空気の境界にかぎらず、あらゆる「界面(異なる物質の境界)」で発生します。リアルな映像表現を行う場合、フレネル方程式を避けて通ることはできません。しかし、フレネル方程式は複雑な計算を必要とします。

>フレネル方程式は以下のURLで確認できます。<br>
>`https://ja.wikipedia.org/wiki/フレネルの式`

前掲のURLを見てみると分かりますが、リアルタイムに計算させるには計算量が多すぎます。そこで、いろいろ違いはあるものの、ある程度同じ反射特性を表現できる「近似式(きんじしき)」が考案されました。

この近似式は、考案者の名前をとって「シュリック(Schlick)の近似式」と呼ばれています。シュリックの近似式は次のように表されます。

$$
F = F0 + (1 - F0)(1 - cosθ)^5
$$

ここで`F0`は「光線が法線と平行な角度(θ=0)で入射した場合の鏡面反射係数」です。`F0`の値は物体によって異なり、非金属の平均値は約`0.04`、金属は`0.5`～`1.0`になります。

それから、BRDFでは表面法線の代わりにハーフベクトルが使われます。これによって、`cosθ`の部分が「入射ベクトルとハーフベクトルの内積」になり、1.1節で見た以下の式につながります。

$$
\begin{aligned}
F0 &= 角度0°のときのフレネル値 \\
F &= F0 + (1 - F0)(1 - L \cdot H)^5 \\
\end{aligned}
$$

近似式なので、式自体に物理的な根拠はありません。とはいえ、`1 - L・H`という式から「入射ベクトルと法線のなす角が0°に近いほど反射が弱くなり、90°に近いほど反射が強くなる」ことが分かります。

この式によって「見る角度によって反射率が異なる」という挙動を再現しています。

それではフレネル項を扱う関数を定義しましょう。名前は`FresnelSchlick`(フレネル・シュリック)とします。`GeometricAttenuationSchlick`関数の定義の下に、次のプログラムを追加してください。

```diff
   // 視点方向から見た幾何学的減衰項を計算
   float g1 = NdotV / (NdotV * (1 - k) + k);

   return g0 * g1;
 }
+
+/**
+* フレネル項
+*/
+vec3 FresnelSchlick(vec3 f0, float VdotH)
+{
+  // シュリックの近似式
+  float vh1 = 1 - VdotH;
+  float vh2 = vh1 * vh1;
+  return f0 + (1 - f0) * (vh2 * vh2 * vh1);
+}

 /**
 * エントリーポイント
 */
 void main()
```

この定義では、引数を`LdotH`ではなく`VdotH`にしていることに注意してください。ハーフベクトル`H`は`L`と`V`の中間ベクトルなので、`LdotH`と`VdotH`は常に同じ値になります。そのため、交換しても問題ないのです。

なお、「角度0°のときのフレネル項の値」は`vec3`で受け取ります。非金属ではRGBによる違いはないので`float`で十分です。しかし、金属の場合はRGBごとに値が異なり、それが金属特有の色合いになります。

これでフレネル項は完成です。

### 1.5 鏡面反射BRDF関数を定義する

ここまでのプログラムで、鏡面反射BRDFに必要な「法線分布項`D`」「幾何減衰項`G`」「フレネル項`F`」が揃いました。この3つを組み合わせて鏡面反射BRDFを求める関数を定義しましょう。

$$
鏡面反射BRDF = \dfrac{D * G * F}{4(N \cdot L)(N \cdot V)}
$$

関数名は`SpecularBRDF`(スペキュラ・ビーアールディーエフ)とします。`FresnelSchlick`関数の定義の下に、次のプログラムを追加してください。

```diff
   float hv1 = 1 - VdotH;
   float hv2 = hv1 * hv1;
   return f0 + (1 - f0) * (hv2 * hv2 * hv1);
 }
+
+// cosθの最小値
+const float minCosTheta = 0.000001;
+
+/**
+* 鏡面反射BRDF
+*/
+vec3 SpecularBRDF(vec3 normal, vec3 H, float roughness, vec3 cameraVector, float NdotL, vec3 F)
+{
+  // 法線分布項を計算
+  float D = NormalDistributionGGX(normal, H, roughness);
+
+  // 幾何学的減衰項を計算
+  float NdotV = max(dot(normal, cameraVector), minCosTheta);
+  float G = GeometricAttenuationSchlick(NdotL, NdotV, roughness);
+
+  // 鏡面反射BRDFを計算
+  float denom = 4 * NdotL * NdotV;
+  return (D * G * F) * (1 / denom);
+}

 /**
 * エントリーポイント
 */
 void main()
```

鏡面反射BRDFの計算で登場するパラメータのうち、`N・L`、`F`、`H`は他の計算でも使用します。そこで、引数として受け取るようにしています。

`N・L`は拡散反射BRDFで使います。フレネル項`F`拡散反射BRDFと鏡面反射BRDFの合成で使います。`H`はフレネル項`F`の計算で使います。

鏡面反射BRDFの式の分母`4(N・L)(N・V)`は、`D * G * F`を正規化するための係数です。この係数によって、`入射光 = 鏡面反射 + 拡散反射`が成立するように鏡面反射BRDFの値を調整します。

### 1.6 BRDFの計算に必要なユニフォーム変数を追加する

鏡面反射BRDFを計算するために、`standard.frag`に不足しているラフネスと視線ベクトルを追加します。ただし、視線ベクトルはフラグメントによって異なります。そこで、追加するのは「視点(カメラ)座標」とします。

視線ベクトルは「視点座標 - フラグメントの座標」で求められます。フラグメントの座標は`inPosition`として定義済みなので、あとは視点座標があればいいわけです。

それでは、`standard.frag`を開き、ユニフォーム変数の定義に次のプログラムを追加してください。

```diff
 // 出力する色データ
 out vec4 outColor;
+
+layout(location=4) uniform vec3 cameraPosition; // カメラ座標

 layout(location=100) uniform vec4 color; // 物体の色
 layout(location=101) uniform vec4 emission; // 物体の発光色
 layout(location=102) uniform float alphaCutoff; // フラグメントを破棄する境界値
+
+// x=物体表面の粗さ y=金属かどうか(0=非金属 1=金属)
+layout(location=103) uniform vec2 roughnessAndMetallic;

 // 環境光
 layout(location=107) uniform vec3 ambientLight;
```

カメラ座標のロケーション番号は、頂点シェーダと同じにしています。複数のシェーダで同一のロケーション番号を指定すると、ひとつのユニフォーム変数を共有できます。

>`standard.vert`の`cameraPosition`ユニフォーム変数の定義を確認しなさい。もしロケーション番号が異なっていたら、`standard.vert`側に合わせなさい。同じ場合は何もする必要はありません。

ロケーション番号の消費を抑えるため、ラフネスとメタリックはひとつの`vec2`にまとめて定義することにしました。

>**【alphaCutoffをまとめない理由】**<br>
>`alphaCutoff`とまとめて`vec3`にすることも考えました。しかし、ラフネスとメタリックはマテリアルごとに書き換えますが、`alphaCutoff`は描画全体で見てもあまり変更されません。このように有効期間が大きく異なる変数をまとめてしまうと、有効期間が長い変数を無駄に書き換えることになってしまいます。有効期間が大きく異なるユニフォーム変数は、多少ロケーション番号が無駄になるとしても、分けておくことでトータルの書き換え量を減らせます。

### 1.7 鏡面反射BRDFと拡散反射BRDFを計算する関数を定義する

次に、鏡面反射BRDFと拡散反射BRDFをまとめて計算する関数を定義します。関数名は`CalcBRDF`(カルク・ビーアールディーエフ)とします。`SpecularBRDF`関数の定義の下に、次のプログラムを追加してください。

```diff
   // 鏡面反射を計算
   float denom = 4 * max(NdotL * NdotV, minCosTheta);
   return (D * G * F) * (1 / denom);
 }
+
+// CalcBRDFの計算結果
+struct BRDFResult
+{
+  vec3 diffuse;  // 拡散反射
+  vec3 specular; // 鏡面反射
+};
+
+/**
+* 鏡面反射BRDFと拡散反射BRDFをまとめて計算する
+*/
+BRDFResult CalcBRDF(vec3 normal, vec3 f0,
+  vec3 cameraVector, vec3 direction, vec3 color)
+{
+  // フレネルを計算
+  vec3 H = normalize(direction + cameraVector);
+  vec3 F = FresnelSchlick(f0, max(dot(cameraVector, H), 0));
+
+  // GGXで鏡面反射を計算
+  float NdotL = max(dot(normal, direction), minCosTheta);
+  vec3 specularBRDF = SpecularBRDF(
+    normal, H, roughnessAndMetallic.x, cameraVector, NdotL, F);
+  vec3 specular = color * specularBRDF * NdotL;
+
+  // 正規化ランバートで拡散反射を計算
+  float diffuseBRDF = NdotL / 3.14159265;
+  vec3 diffuse = color * diffuseBRDF * (1 - F) * (1 - roughnessAndMetallic.y);
+
+  return BRDFResult(diffuse, specular);
+}

 /**
 * エントリーポイント
 */
 void main()
```

拡散反射BRDFは、現在のシェーダと同じく「正規化ランバート」によって計算します。

フレネル効果により、角度90°では`F`が`1.0`になります。このとき、`(1 - F)`は0になります。つまり、角度90°では拡散反射は起きず、入射光は100%鏡面反射されるわけです。

>フレネル効果は現実の物体でも見られます。現実の光は複雑なので全く同じに見えるわけではありませんが、光沢のあるコップなどを観察してみるとフレネル効果が実感できるでしょう。

また、メタリックが`1`のとき、つまり金属マテリアルを描画するときは、拡散反射が無効化されることに注意してください。これは、「金属は拡散反射を起こさない」という物理現象を再現するためです。

### 1.8 BRDFの計算に共通の変数を計算する

それでは、追加したユニフォーム変数を使ってBRDFを計算しましょう。まず、すべてのライトで共通して使われる値を計算します。`main`関数の定義に次のプログラムを追加してください。

```diff
   outColor = c * color;

   // 線形補間によって長さが1ではなくなっているので、正規化して長さを1に復元する
   vec3 normal = normalize(inNormal);
+
+  // 視線ベクトル
+  vec3 cameraVector = normalize(cameraPosition - inPosition);
+
+  // 角度0のフレネル値
+  vec3 f0 = mix(vec3(0.04), outColor.rgb, roughnessAndMetallic.y);

   vec3 diffuse = vec3(0); // 拡散光の明るさの合計
+  vec3 specular = vec3(0);// 鏡面反射光の明るさの合計
   for (int i = 0; i < lightCount; ++i) {
     // 光源の方向
     vec3 direction = pointLight.positionAndRadius[i].xyz - inPosition;
```

角度0°のときのフレネル値`f0`の計算では、メタリックが`0`、つまり材質が非金属のとき`0.04`が設定されます。`0.04`は非金属の平均的なフレネル値で、「入射光の4%が鏡面反射になる」ことを意味します。

### 1.9 拡散光の計算をBRDFの計算に置き換える

これまで拡散光だけを計算していた部分をBRDFの計算で置き換えていきましょう。まず、`theta`は`CalcBRDF`関数内で計算するので削除します。これにより`illuminance`の初期値も変更されます。

`for`ループ内にある`theta`と`illuminance`を定義するプログラムを、次のように変更してください。

```diff
     // 方向を正規化して長さを1にする
     direction = normalize(direction);
-
-    // ランベルトの余弦則を使って明るさを計算
-    float theta = max(dot(direction, normal), 0);
-
-    // ランバート反射による反射光のエネルギー量を入射光と等しくするためにπで割る
-    float illuminance = theta / 3.14159265; 合計後に一括で乗算するように遅延
+    float illuminance = 1;

    // 照射角度が0より大きければスポットライトとみなす
    const float coneAngle = Get(pointLight.directionAndConeAngle, i).w;
    if (coneAngle > 0) {
```

次に、ポイントライトおよびスポットライトの拡散光の明るさを計算するプログラムを、次のように`CalcBRDF`関数で置き換えてください。

```diff
     // 逆2乗の法則によって明るさを減衰させる
     illuminance /= sqrDistance + 1;

-    // 拡散光の明るさを計算
-    diffuse += pointLight.colorAndFalloffAngle[i].xyz * illuminance;
+    // 拡散反射と鏡面反射を計算
+    vec3 color = pointLight.colorAndFalloffAngle[i].xyz * illuminance;
+    BRDFResult result = CalcBRDF(normal, f0, cameraVector, direction, color);
+    diffuse += result.diffuse;
+    specular += result.specular;
   } // for lightCount

   // 影を計算
   vec3 shadowXYZ = vec3(clamp(inShadowTexcoord.xy, 0, 1), inShadowTexcoord.z);
```

続いて、ディレクショナルライト(平行光源)の各参考の明るさを計算するプログラムを、`CalcBRDF`関数で置き換えてください。

```diff
   // 影を計算
   vec3 shadowXYZ = vec3(clamp(inShadowTexcoord.xy, 0, 1), inShadowTexcoord.z);
   float shadow = texture(texShadow, shadowXYZ).r;

   // 平行光源の明るさを計算
-  float theta = max(dot(-directionalLight.direction, normal), 0);
-  float illuminance = theta / 3.14159265;
-  diffuse += directionalLight.color * illuminance * shadow;
+  BRDFResult result = CalcBRDF(normal, f0, cameraVector,
+    -directionalLight.direction, directionalLight.color);
+  specular += result.specular * shadow;
+  diffuse += result.diffuse * shadow;

   // アンビエントライトの明るさを計算
   diffuse += ambientLight;
```

本テキストでは、平行光源のみ`shadow`変数の影響を受けることに注意してください。ポイントライトやスポットライトの影まで計算すると、計算にかなり時間がかかるため省略しています。

### 1.10 アンビエントライトをラフネスとメタリックに対応させる

アンビエントライトは、拡散反射成分と鏡面反射成分に分けて処理するようにします。アンビエントライトの明るさを計算するプログラムを、次のように変更してください。

```diff
   BRDFResult result = CalcBRDF(normal, f0, cameraVector,
     -directionalLight.direction, directionalLight.color);
   specular += result.specular * shadow;
   diffuse += result.diffuse * shadow;

   // アンビエントライトの明るさを計算
-  diffuse += ambientLight;
+  vec3 Fa = f0 + (1 - f0) * 0.0021555; // 角度45°のフレネル値
+  specular += ambientLight * Fa;
+  diffuse += ambientLight * (1 - Fa) * (1 - roughnessAndMetallic.y);

   // 拡散光の影響を反映
   outColor.rgb *= diffuse;
```

アンビエントライトは「すべての方向からの光の平均値」なので、フレネル値も「物体を見るときの平均的な角度」を選ぶ必要があります。

球体を正面から見たとき、角度45°境界の内側と外側の見かけの面積は等しくなります。そこで、「cos(45°)の5乗」を電卓で計算して`0.00021555`を求めました。

### 1.11 鏡面反射を反映する

最後に、ここまでに計算した鏡面反射の影響を反映します。拡散光の影響を反映するプログラムの下に、次のプログラムを追加してください。

```diff
   specular += ambientLight * Fa;
   diffuse += ambientLight * (1 - Fa) * (1 - roughnessAndMetallic.y);

   // 拡散光の影響を反映
   outColor.rgb *= diffuse;
+
+  // 鏡面反射の影響を反映
+  outColor.rgb += specular;

   // 発光色を反映
   if (emission.w > 0) {
```

これで、シェーダ側の変更は完了です。

### 1.12 マテリアルにラフネスとメタリックを設定する

ここからは、C++プログラム側に機能を追加していきます。手始めに`Material`構造体にラフネスとメタリックを追加しましょう。`Mesh.h`を開き、`Material`構造体に次のプログラムを追加してください。

```diff
   std::string name = "<Default>";  // マテリアル名
   vec4 baseColor = { 1, 1, 1, 1 }; // 基本色+アルファ
   vec3 emission = { 0, 0, 0 };     // 発光色
+  float roughness = 0.7f;          // 表面の粗さ
+  float metallic = 0.0f;           // 0=非金属 1=金属
   TexturePtr texBaseColor;         // 基本色テクスチャ
   TexturePtr texEmission;          // 発光色テクスチャ
```

### 1.13 MTLファイルからラフネスの値を読み取る

次に、MTLファイルの構文を解釈して、追加した`roughness`(ラフネス)メンバ変数と`metallic`(メタリック)メンバ変数に値を設定します。

MTLファイルにおいて、鏡面反射は「RGBごとの鏡面反射率(スペキュラ色)」を表す`Ks`(ケーエス)構文と、「なめらかさ(スペキュラ係数)」を表す`Ns`(エヌエス)構文の2つで定義されます。

とりあえず、これらの構文を読み込みましょう。最初に読み取り用の変数を定義します。`Mesh.cpp`を開き、`LoadMTL`メンバ関数の定義に次のプログラムを追加してください。

```diff
   // MTLファイルを解析する
   std::vector<MaterialPtr> materials;
   MaterialPtr pMaterial;
+  vec3 specularColor = vec3(1); // スペキュラ色
+  float specularPower = 12;     // スペキュラ係数
   while (!file.eof()) {
     std::string line;
     std::getline(file, line);
```

次に、読み取った2つのパラメータからラフネスを計算し、マテリアルに設定します。マテリアル定義を読み取るプログラムに、次のプログラムを追加してください。

```diff
     // マテリアル定義の読み取りを試みる
     char name[1000] = { 0 };
     if (sscanf(line.data(), " newmtl %[^\n]s", name) == 1) {
+      if (pMaterial) {
+        // スペキュラの2つのパラメータからラフネスを計算
+        specularPower *= std::max(std::max(specularColor.x, specularColor.y), specularColor.z);
+        pMaterial->roughness = std::clamp(1 - log2(specularPower) / 12, 0.0001f, 1.0f);
+
+        // スペキュラパラメータを初期値に戻す
+        specularColor = vec3(1);
+        specularPower = 12;
+
+        // テクスチャが設定されていないマテリアルの場合、white.tgaを設定しておく
+        if (!pMaterial->texBaseColor) {
+          pMaterial->texBaseColor = textureCallback("Res/white.tga");
+        }
       }
       pMaterial = std::make_shared<Material>();
       pMaterial->name = name;
       materials.push_back(pMaterial);
```

本来、スペキュラ色はRGBで異なる可能性があります。しかし、2024年現在の3Dモデル作成ではRGB全てに同じ値を設定することが一般的です。今回の描画でもRGBは区別しません。

とはいえ、同じ値が設定されている保証はありませんから、`max`関数を用いてRGBのうち最大値を使うようにしてみました。

ラフネスはスペキュラ係数から計算します。MTLファイルの仕様では、スペキュラ係数が取りうる値は`1`～`1000`とされています。定義によると、この値は鏡面反射計算において「指数」として扱う必要があります。

ラフネスには線形の値を指定しなくてはならないので、指数から線形数に変換する必要があります。これには`log2`関数が利用できます。

`log2`関数は、引数Aについて

$$
A=2^N
$$

となるNを返します。例えば引数が`16`のとき、`16`は`2`の`4`乗なので、戻り値は`4`になります。

スペキュラ係数の最大値1000は「`2`の10乗」に近いです。そこで、`log2`関数を使ってスペキュラ係数を対数に変換するとだいたい0～10の範囲が得られます。これを10で割ることで、`0.0`～`1.0`の範囲にしています。

ただし、ラフネスが`0.0`だとBRDFの計算において除数が0になってしまい計算できません。ここでは`clamp`関数を使って最小値を`0.0001f`とすることで0除算を回避しています。

最後に作成したマテリアルのために、同様の処理を`while`文の直後にも追加してください。

```diff
         LOG_WARNING("%sを開けません", filename.c_str());
       }
       continue;
     }
   }
+
+  // 最後のマテリアルのスペキュラパラメータを設定
+  if (pMaterial) {
+    // スペキュラの2つのパラメータからラフネスを計算
+    specularPower *= std::max(std::max(specularColor.x, specularColor.y), specularColor.z);
+    pMaterial->roughness = std::clamp(1 - log2(specularPower) / 12, 0.0001f, 1.0f);
+
+    // テクスチャが設定されていないマテリアルの場合、white.tgaを設定しておく
+    if (!pMaterial->texBaseColor) {
+      pMaterial->texBaseColor = textureCallback("Res/white.tga");
+    }
+  }

   // 読み込んだマテリアルの配列を返す
   LOG("%sを読み込みました", fullpath.c_str());
   return materials;
```

それでは、`Ks`構文を解析しましょう。`while`文の中にある光色テクスチャ名を読み取るプログラムの下に、次のプログラムを追加してください。

```diff
         pMaterial->texEmission =
           textureCallback(filename.c_str());
       } else {
         LOG_WARNING("%sを開けません", filename.c_str());
       }
       continue;
     }
+
+    // スペキュラ色の読み取りを試みる
+    if (sscanf(line.data(), " Ks %f %f %f",
+      &specularColor.x, &specularColor.y, &specularColor.z) == 3) {
+      continue;
+    }
   }

   // 読み込んだマテリアルの配列を返す
   LOG("%sを読み込みました", fullpath.c_str());
```

続いて`Ns`構文を解析します。`Ks`を解析するプログラムの下に、次のプログラムを追加してください。

```diff
       &specularColor.x, &specularColor.y, &specularColor.z) == 3) {
       continue;
     }
+
+    // スペキュラ係数の読み取りを試みる
+    if (sscanf(line.data(), " Ns %f", &pMaterial->specularPower) == 1) {
+      continue;
+    }
   }

   // 読み込んだマテリアルの配列を返す
   LOG("%sを読み込みました", fullpath.c_str());
```

これで、スペキュラ係数からラフネスを取得できるようになりました。

### 1.14 MTLファイルからメタリックを読み取る

次にメタリックを読み取ります。ただし、メタリックはMTLファイルには標準機能としては存在しません。ただし、一部のツールは`Pm`という構文でメタリックを表現しています。

そこで、本テキストでも`Pm`構文によってメタリックに対応することにします。スペキュラ係数を読み取るプログラムの下に、次のプログラムを追加してください。

```diff
     // スペキュラ係数の読み取りを試みる
     if (sscanf(line.data(), " Ns %f", &pMaterial->specularPower) == 1) {
       continue;
     }
+
+    // メタリックの読み取りを試みる
+    if (sscanf(line.data(), " Pm %f", &pMaterial->metallic) == 1) {
+      continue;
+    }
   }

   // 読み込んだマテリアルの配列を返す
   LOG("%sを読み込みました", fullpath.c_str());
```

これで、金属マテリアルと非金属マテリアルを使い分けられるようになりました。

### 1.15 ProgramObjectクラスにロケーション番号を扱う機能を追加する

メタリックやラフネスのように特定のシェーダにしか存在しないユニフォーム変数は、それらのユニフォーム変数を持たないシェーダに対して`glUniform`系の関数を呼び出すと失敗します。

エラーを発生させないためには、`glUniform`系の関数を呼ぶ前に特定のユニフォーム変数を持つかどうかを判定できなくてはなりません。

あるシェーダが特定のロケーション番号を持つかどうかは、`glGetUniformLocation`(ジーエル・ゲット・ユニフォーム・ロケーション)関数によって調べられます。

ただ、この関数は文字列比較を行うため、頻繁に呼び出すとプログラムの実行速度が落ちてしまいます。そこで、シェーダを読み込んだ時点で一度だけ`glGetUniformLocation`関数を呼び出すことにします。

このときの結果を記録しておけば、以後は簡単にユニフォーム変数の有無を判定できます。シェーダに関する機能なので、`ProgramObject`クラスに追加するのが適当でしょう。

`ProgramObject.h`を開き、`ProgramObject`クラスの定義に次のプログラムを追加してください。

```diff
   // 管理番号を取得
   operator GLuint() const { return prog; }
+
+  // ロケーション番号を取得
+  GLint ColorLocation() const { return locColor; }
+  GLint RoughnessAndMetallicLocation() const { return locRoughnessAndMetallic; }

 private:
   GLuint vs = 0;          // 頂点シェーダ
   GLuint fs = 0;          // フラグメントシェーダ
   GLuint prog = 0;        // プログラムオブジェクト
   std::string filenameFS; // フラグメントシェーダファイル名
   std::string filenameVS; // 頂点シェーダファイル名
+  GLint locColor = -1;
+  GLint locRoughnessAndMetallic = -1;
 };

 #endif // PROGRAMOBJECT_H_INCLUDED
```

次に`ProgramObject.cpp`を開き、`ProgramObject`コンストラクタの定義に次のプログラムを追加してください。

```diff
   if (status != GL_TRUE) {
     LOG_ERROR("シェーダのリンクに失敗(vs=%s, fs=%s)", filenameVS, filenameFS);
     return;
   }
+
+  // ロケーション番号を取得
+  locColor = glGetUniformLocation(prog, "color");
+  locRoughnessAndMetallic = glGetUniformLocation(prog, "roughnessAndMetallic");

   LOG("シェーダを作成(vs=%s, fs=%s)", filenameVS, filenameFS);
 }
```

ユニフォーム変数のロケーション番号を取得するには`glGetUniformLocation`関数を使います。

<p><code class="tnmai_code"><strong>【書式】</strong><br>
GLint glGetUniformLocation(シェーダプログラムの管理番号, ユニフォーム変数名);
</code></p>

この関数は、「ユニフォーム変数名」で指定した名前のユニフォーム変数のロケーション番号を返します。シェーダプログラムに「ユニフォーム変数名」のユニフォーム変数が存在しない場合は負数を返します。

戻り値の性質から、「ロケーション番号が負数の場合は、ユニフォーム変数が存在しない」ことが分かります。

### 1.16 Draw関数をラフネスとメタリックに対応させる

次に、メッシュの`Draw`関数をラフネスとメタリックに対応させます。`Mesh.cpp`を開き、`Mesh`用の`Draw`関数の定義を次のように変更してください。

```diff
 void Draw(const std::vector<DrawParams>& drawParamsList,
   const ProgramObject& program,
   const MaterialList& materials, const vec4* objectColor)
 {
+  const GLint locRoughnessAndMetallic = program.RoughnessAndMetallicLocation();
+
   for (const auto& e : drawParamsList) {
     // マテリアルを設定
     if (e.materialNo >= 0 && e.materialNo < materials.size()) {
       const Material& material = *materials[e.materialNo];
       if (objectColor) {
         const vec4 color = *objectColor * material.baseColor;
         glProgramUniform4fv(program, 100, 1, &color.x);
         glProgramUniform4f(program, 101,
           material.emission.x, material.emission.y, material.emission.z,
           static_cast<bool>(material.texEmission));
       }
+
+      // ラフネスとメタリックを設定
+      if (locRoughnessAndMetallic >= 0) {
+        glProgramUniform2f(program, locRoughnessAndMetallic,
+          material.roughness, material.metallic);
+      }

       if (material.texBaseColor) {
         const GLuint tex = *material.texBaseColor;
         glBindTextures(0, 1, &tex);
```

プログラムが書けたらビルドして実行してください。周囲の物体に光沢がついていたら成功です。

<p align="center">
<img src="images/22_result_0.jpg" width="45%" /><br>
[地面や木の葉に白い光沢が見える]
</p>

<pre class="tnmai_assignment">
<strong>【課題01】</strong>
地面モデルのMTLファイルのNs構文の値を300に設定して、鏡面反射の変化を確かめなさい。地面モデルにNs構文が定義されていない場合は新しく追加すること。
</pre>

<pre class="tnmai_assignment">
<strong>【課題02】</strong>
地面モデルのMTLファイルにPm構文を追加し、値を1に設定して、金属の表示のされ方を確かめなさい。
</pre>

>**【1章のまとめ】**
>
>* 光の反射には「拡散反射」と「鏡面反射」がある。
>* BRDFは「双方向反射率分布関数」のこと。「ある方向からの入射光が、別のある方向(例えば視点方向)に出射する比率」を求めることができる。
>* マイクロファセットBRDFは、物体表面を微小平面(マイクロファセット)の集合として考えるBRDFのこと。
>* マイクロファセットBRDFは、「法線分布項`D`」「幾何減衰項`G`」「フレネル項`F`」を組み合わせて作られる。

<div style="page-break-after: always"></div>

## 2. 法線(ノーマル)マッピング

### 2.1 なぜ法線マッピングを行うのか

<p align="center">
<img src="images/unsplash.com/vitalijs-barilo-azMZaQCUyV8-unsplash.jpg" width="25%" />
<img src="images/unsplash.com/jonathan-borba-PbwP04DkhQA-unsplash.jpg" width="25%" />
<img src="images/unsplash.com/charlie-firth-6v8GsXKJZI8-unsplash.jpg" width="25%" /><br>
[撮影者 布地:vitalijs barilo 道路:jonathan borba 湖面:charlie firth]
</p>

布地の繊維、アスファルトの凹凸(おうとつ)、水面に立つさざなみなど、現実世界には微細な凹凸が数多く存在します。わたしたちは、こうした物体表面の構造の存在に慣れているため、凹凸の感じられない物体は作り物だと感じてしまいます。

このような微細な凹凸をポリゴンで再現しようとすると、膨大な頂点数が必要となります。実際に、映画用のモデルなどでは、微細な凹凸まで制作される場合があります。しかし、ゲームのようにリアルタイム性が求められるアプリケーションでは現実的とはいえません。

そのため、3Dグラフィックス性能が十分ではなかった頃は、これらの凹凸はカラーテクスチャに陰影を描き込むことで再現していました。

しかし、陰影として描き込まれた凹凸は、どこから見ても、またどのような光の当たり方をしても陰影が変化しません。そのため、すぐにまやかしの影であることがバレてしまいます。

この問題を解決するために生まれたのが「法線マッピング」です。法線マッピングの基本的な考え方は次のようなものです。

>凹凸が陰影を生むのは法線方向が異なるからだ。つまり、法線さえ再現できれば実際に凹凸を作る必要はないはずだ。

法線の再現には、カラーのかわりに「法線の変化量(摂動)」を記録したテクスチャを使います。法線を記録したテクスチャのことを「法線テクスチャ」といいます。

### 2.2 法線マッピングの種類

法線テクスチャに記録する法線(の摂動)には、以下の2種類が存在します。

| 名前 | 記録する法線の種類 |
|:-----|:-----|
| オブジェクト空間法線マッピング | モデル座標系(オブジェクト空間)の法線 |
| タンジェント空間法線マッピング | 図形に接する平面を基準とする座標系(タンジェント空間)の法線 |

実装は「オブジェクト空間法線マッピング」のほうが簡単です。そのかわり、「モデルの変形に対応できない」、「テクスチャの再利用が難しい」という欠点があります。

「タンジェント空間法線マッピング」は、実装が複雑になるかわりに「オブジェクト空間法線マッピング」の欠点が解消されています。そのため、多くの法線テクスチャはタンジェント空間用に作られています。

本テキストでは欠点の少ない「タンジェント空間法線マッピング」を実装することにします。

### 2.3 タンジェント空間

>「座標系」は、「空間において、座標を決めるための基本情報」です。

コンピューターグラフィックスにおける「タンジェント空間」は、「頂点座標に接する、頂点法線に垂直な平面を基準とする座標系」として定義されます。

<p align="center">
<img src="images/Tips_07_tangent_vector.jpg" width="33%" /><br>
[緑=タンジェント(T) 赤=バイタンジェント(B) 青=頂点法線(N)]
</p>

タンジェント空間のX軸は「タンジェントベクトル」と呼ばれます(「タンジェント空間」の名前の由来)。Y軸は「バイタンジェント・ベクトル」と呼ばれます。Z軸は平面の法線で、これは頂点法線と同じです。

タンジェントベクトル`T`とバイタンジェントベクトル`B`は、頂点座標に接する平面上であればどんな向きも取り得ます。これは、「タンジェント空間の座標系の定義は無数に存在する」ことを意味します。

とはいえ、法線を定義するには「無数に存在する」と言われても困ります。そこで、タンジェント空間法線マッピングでは、「TとBがテクスチャ座標系のUV軸の向きと一致する座標系」が選択されます。

この座標系では、テクスチャ座標系のU軸がタンジェントベクトルと一致し、V軸がバイタンジェントベクトルと一致します。実際の利用法にもとづく説明をすると「法線テクスチャに記録する法線ベクトルの基準となる座標系」が選ばれるわけです。

法線テクスチャと3Dモデルは、この座標系によって関連付けられます。

### 2.4 頂点シェーダにタンジェントベクトル変数を追加する

タンジェント空間法線マッピングでは、頂点ごとにタンジェントベクトルを持たせます。

>今回は説明しませんが、頂点に持たせず、シェーダでタンジェントベクトルを計算するやり方もあります。

それから、法線テクスチャを読み込んでシェーダに割り当てる必要もあります。法線テクスチャはマテリアルとして定義するのが一般的です。

これらを実現するために必要な作業は以下のとおりです。

頂点シェーダ:

>1. 法線マッピング用のin変数とout変数を追加。
>2. タンジェント座標系からワールド座標系に変換する行列(TBN行列)を計算。

TBN(ティービーエヌ)は「タンジェント、バイタンジェント、ノーマル」の頭文字です。

フラグメントシェーダ:

>1. TBN行列用のin変数と、法線テクスチャのサンプラを追加。
>2. 法線テクスチャから法線を読み取り、ポリゴン平面の座標系(タンジェント座標系)からワールド座標系に変換。

C++アプリケーション:

>1. `Material`構造体に法線テクスチャ変数を追加。
>2. MTLファイルから法線テクスチャ名を読み取り、法線テクスチャを読み込んで変数に代入。
>3. 描画前に法線テクスチャをバインド。
>4. `Vertex`構造体と`SkeletalVertex`構造体に「タンジェントベクトル」変数を追加。
>5. 頂点アトリビュートに「タンジェントベクトル」を追加。
>6. 「タンジェントベクトル」と「バイタンジェントベクトルの向き」を計算し、タンジェントベクトル変数に代入。

それでは、頂点シェーダから法線マッピングに対応させていきましょう。`standared.vert`を開き、法線マッピング用のin変数とout変数を追加してください。

```diff
 layout(location=0) in vec3 inPosition; // 頂点座標
 layout(location=1) in vec2 inTexcoord; // テクスチャ座標
 layout(location=2) in vec3 inNormal;   // 法線ベクトル
+layout(location=3) in vec4 inTangent;  // タンジェントベクトル
 
 // シェーダからの出力
 layout(location=0) out vec3 outPosition; // ワールド座標
 layout(location=1) out vec2 outTexcoord; // テクスチャ座標
-layout(location=2) out vec3 outNormal;   // 法線ベクトル
-layout(location=3) out vec3 outShadowTexcoord; // シャドウテクスチャ座標
+layout(location=2) out mat3 outTBN;      // 法線変換行列
+layout(location=5) out vec3 outShadowTexcoord; // シャドウテクスチャ座標

 // プログラムからの入力
 layout(location=0) uniform vec3 scale; // 拡大率
```

`outNormal`を削除して、代わりにタンジェント、バイタンジェント、法線の3つをまとめて扱う`outTBN`行列を追加しています。`outTBN`は行列なので`vec3`ではなく`mat3`になる点に注意してください。

また、ユニフォーム変数とは異なり、`in`, `out`変数では実際のサイズに応じてロケーション番号を消費します。つまり`mat3`は3つのロケーション番号を使うわけです。

そのため、`outShadowTexcoord`のロケーション番号を`5`に変更しています。

次に、法線ベクトルとタンジェントベクトルからバイタンジェントベクトルを計算し、TBN(ティービーエヌ)行列を作成します。ワールド法線を計算するプログラムを次のように変更してください。

```diff
   gl_Position = transformMatrix * vec4(inPosition, 1);

   outPosition = gl_Position.xyz;

   // ワールド法線を計算
-  outNormal = normalMatrix * inNormal;
+  outTBN[0] = normalMatrix * inTangent.xyz;
+  outTBN[2] = normalMatrix * inNormal;
+  outTBN[1] = inTangent.w * cross(outTBN[2], outTBN[0]);

   // シャドウテクスチャ座標を計算
-  outShadowTexcoord = outPosition + outNormal * shadowNormalOffset;
+  outShadowTexcoord = outPosition + outTBN[2] * shadowNormalOffset;
   outShadowTexcoord = vec3(shadowTextureMatrix * vec4(outShadowTexcoord, 1));

   // ワールド座標系からビュー座標系に変換
   vec3 pos = gl_Position.xyz - cameraPosition;
```

タンジェントベクトルは法線と同じ「向きベクトル」です。そのため、平行移動を含まない`matNormal`行列を使ってワールド座標系に変換します。

### 2.5 skeleta.vertにタンジェントベクトル変数を追加する

3Dモデルの座標変換は`skeletal.vert`でも行っているので、同じ変更を行います。`skeletal.vert`を開き、法線マッピング用のin変数とout変数を追加してください。

```diff
 layout(location=0) in vec3 inPosition; // 頂点座標
 layout(location=1) in vec2 inTexcoord; // テクスチャ座標
 layout(location=2) in vec3 inNormal;   // 法線ベクトル
+layout(location=3) in vec4 inTangent;  // 接線ベクトル
-layout(location=3) in uvec4 inJoints;  // 座標変換行列の番号
-layout(location=4) in vec4 inWeights;  // 座標変換行列の影響度
+layout(location=4) in uvec4 inJoints;  // 座標変換行列の番号
+layout(location=5) in vec4 inWeights;  // 座標変換行列の影響度
 
 // シェーダからの出力
 layout(location=0) out vec3 outPosition; // ワールド座標
 layout(location=1) out vec2 outTexcoord; // テクスチャ座標
-layout(location=2) out vec3 outNormal;   // 法線ベクトル
-layout(location=3) out vec3 outShadowTexcoord; // シャドウテクスチャ座標
+layout(location=2) out mat3 outTBN;      // 法線変換行列
+layout(location=5) out vec3 outShadowTexcoord; // シャドウテクスチャ座標
 
 // プログラムからの入力
 layout(location=0) uniform mat4 transformMatrix;
```

次に、`main`関数にあるワールド法線を計算するプログラムを、次のように変更してください。

```diff
   // ワールド法線を計算
   mat3 jointNormalMatrix = inverse(transpose(mat3(modelMatrix))); 
-  outNormal = normalize(jointNormalMatrix * inNormal);
+  outTBN[0] = normalize(jointNormalMatrix * inTangent.xyz);
+  outTBN[2] = normalize(jointNormalMatrix * inNormal);
+  outTBN[1] = normalize(inTangent.w * cross(outTBN[2], outTBN[0]));

   // シャドウテクスチャ座標を計算
-  outShadowTexcoord = outPosition + outNormal * shadowNormalOffset;
+  outShadowTexcoord = outPosition + outTBN[2] * shadowNormalOffset;
   outShadowTexcoord = vec3(shadowTextureMatrix * vec4(outShadowTexcoord, 1));

   // ワールド座標系からビュー座標系に変換
   vec3 pos = gl_Position.xyz - cameraPosition;
```

これで、頂点シェーダの変更は完了です。

### 2.6 フラグメントシェーダに法線マッピング用の変数を追加する

続いて、フラグメントシェーダを法線マッピングに対応させます。まず法線マッピング用の変数を追加しましょう。`standard.frag`を開き、変数定義を次のように変更してください。

```diff
 // シェーダへの入力
 layout(location=0) in vec3 inPosition; // ワールド座標
 layout(location=1) in vec2 inTexcoord; // テクスチャ座標
-layout(location=2) in vec3 inNormal;   // 法線ベクトル
-layout(location=3) in vec3 inShadowTexcoord; // シャドウテクスチャ座標
+layout(location=2) in mat3 inTBN;      // 法線変換行列
+layout(location=5) in vec3 inShadowTexcoord; // シャドウテクスチャ座標

 // テクスチャサンプラ
 layout(binding=0) uniform sampler2D texColor;
 layout(binding=1) uniform sampler2D texEmission;
 layout(binding=2) uniform sampler2DShadow texShadow; // 影用の深度テクスチャ
+layout(binding=3) uniform sampler2D texNormal; // 法線テクスチャ

 // 出力する色データ
 out vec4 outColor;
```

### 2.6 法線テクスチャの値をワールド座標系に変換する

タンジェントマッピング法線テクスチャから値を読み取り、ワールド座標系に変換します。法線を正規化するプログラムを次のように変更してください。

```diff
   // テクスチャのガンマ補正を解除
   const float crtGamma = 2.2;
   c.rgb = pow(c.rgb, vec3(2.2));

   outColor = c * color;

-  // 線形補間によって長さが1ではなくなっているので、正規化して長さを1に復元する
-  vec3 normal = normalize(inNormal);
+  // 法線の長さが0でなければ、法線テクスチャが設定されていると判断する
+  vec3 normal = texture(texNormal, inTexcoord).xyz;
+  if (dot(normal, normal) > 0.0001) {
+    // 8bit値であることを考慮しつつ0～1を-1～+1に変換
+    // この式を使うと8bitの128がちょうど0になる
+    normal = normal * (255.0 / 127.0) - (128.0 / 127.0);
+
+    // タンジェント座標系からワールド座標系に変換
+    // 線形補間によってoutTBNの長さが1ではなくなっているので、正規化して長さを1に復元する
+    normal = normalize(inTBN * normal);
+  } else {
+    // 法線テクスチャが未設定の場合は頂点法線を使う
+    normal = normalize(inTBN[2]);
+  }

   // カメラの方向
   vec3 cameraVector = normalize(cameraPosition - inPosition);
```

ここではいくつかの技法を使っています。


法線テクスチャは常にRGBのいずれかの要素に値が格納されるため、`texNormal`に法線テクスチャが割り当てられていれば`dot(normal, normal)`は常に0より大きくなります。

しかし、`texNormal`にテクスチャが割り当てられていない場合、`texture`関数の戻り値は`{ 0, 0, 0, 0 }`になります。結果的に`dot(normal, normal)`も`0`になります。

この`texture`関数の性質を利用して、法線テクスチャが割り当てられている場合のみ法線マッピングを行うようにしています。

それから、法線テクスチャは単なるカラーテクスチャなので、`0`～`1`の値として読み取られます。しかし、実際にはこの値は法線なので、`-1`～`+1`として解釈し直さなくてはなりません。

テクスチャカラーを`t`、変換後の法線を`n`とすると、簡単に思いつくのは以下の式です。

$$
n = t * 2 - 1
$$

しかし、この式には「`0`を表現できない」という問題があります。

どういうことかというと、通常のカラーテクスチャは8bitなので、0～255までの256段階の値しか記録できません。GPUはこれをそのまま0.0～1.0に割り当てます。結果は、以下のようになります。

| 8bit整数 | 浮動小数点数 |
|:---:|:---:|
|   0 | 0.0 |
|  ︙ |  ︙ |
| 127 | 0.49803921568 |
| 128 | 0.50196078431 |
|  ︙ |  ︙ |
| 255 | 1.0 |

式`t * 2 - 1`によって`n`を`0`にするには`t = 0.5`でなくてはなりませんが、8bit整数では`0.5`が表現できません。

そして、`0`を表現できないことの何が問題かというと、「頂点法線と正確に一致する法線テクスチャの値」が定義できないことです。

頂点法線と正確に一致させるには`(0, 0, 1)`という値が必要になります。しかし、式`t * 2 - 1`では`0`を表現できないのでこの値を再現できません。

そこで、`0`を表現できるように式を調整します。こうして調整したものが

$$
n = t * 255 / 127 - 128 / 127
$$

という式です。この式を使うと8bit整数は次のように変換されます。

| 8bit整数 | t\*255/127 - 128/127 |
|:---:|:---:|
|   0 | -1.00787401575 |
|   1 | -1.0 |
|  ︙ |  ︙ |
| 127 |-0.00787401574 |
| 128 | 0.0 |
|  ︙ |  ︙ |
| 255 | 1.0 |

最初の`0`を除くと、`1`が`-1.0`, `128`が`0.0`, `255`が`1.0`に変換されるという、理想的な変換が行われていることが分かります。この式を使うことで、頂点法線と一致する`(0, 0, 1)`が再現できます。

こうして`-1`～`+1`の値に変換したものが、タンジェント座標系の法線ベクトルになります。これに`outTBN`行列を乗算すると、ワールド座標系の法線ベクトルが求められます。

これで、フラグメントシェーダの変更は完了です。

### 2.7 Material構造体に法線テクスチャ変数を追加する

ここからは、CPPアプリケーション側を法線マッピングに対応させていきます。まずマテリアルに法線テクスチャ変数を追加します。`Mesh.h`を開き、`Material`構造体の定義に次のプログラムを追加してください。

```diff
   float metallic = 0.0f;           // 0=非金属 1=金属
   TexturePtr texBaseColor;         // 基本色テクスチャ
   TexturePtr texEmission;          // 発光色テクスチャ
+  TexturePtr texNormal;            // 法線テクスチャ
 };
 using MaterialPtr = std::shared_ptr<Material>;
```

次に、追加した`texNormal`にテクスチャを読み込みます。`Mesh.cpp`を開き、`LoadMTL`関数にある発光色テクスチャを読み取りを試みるプログラムの下に、次のプログラムを追加してください。

```diff
         LOG_WARNING("%sを開けません", filename.c_str());
       }
       continue;
     }
+
+    // 法線テクスチャ名の読み取りを試みる
+    if (sscanf(line.data(), " map_%*[Bb]ump %[^\n]s", &textureName) == 1 ||
+      sscanf(line.data(), " %*[Bb]ump %[^\n]s", &textureName) == 1) {
+      const std::string filename = foldername + textureName;
+      if (std::filesystem::exists(filename)) {
+        pMaterial->texNormal = textureCallback(filename.c_str());
+      } else {
+        LOG_WARNING("%sを開けません", filename.c_str());
+      }
+      continue;
+    } // map_bump

     // スペキュラ色の読み取りを試みる
     if (sscanf(line.data(), " Ks %f %f %f",
```

MTLファイルにおける法線テクスチャの構文は`bump`です。しかし、`map_bump`という構文も広く使われているため、両方に対応させることにしました。

また、エクスポータによっては`bump`ではなく`Bump`という名前で出力されるため、`scanf`の機能を利用して`b`と`B`のどちらでも読み込めるようにしています。

### 2.8 法線テクスチャをGLコンテキストに割り当てる

読み込んだテクスチャを使うには、GLコンテキストに割り当てなくてはなりません。描画パラメータ配列を描画する`Draw`関数の定義に、次のプログラムを追加してください。

```diff
       if (material.texEmission) {
         const GLuint tex = *material.texEmission;
         glBindTextures(1, 1, &tex);
       } else {
         glBindTextures(1, 1, nullptr);
       }
+      if (material.texNormal) {
+        const GLuint tex = *material.texNormal;
+        glBindTextures(3, 1, &tex);
+      } else {
+        glBindTextures(3, 1, nullptr);
+      }
     }

     glDrawElementsBaseVertex(
       e.mode, e.count, GL_UNSIGNED_SHORT, e.indices, e.baseVertex);
```

これで法線テクスチャの設定は完了です。

### 2.9 Vertex構造体にタンジェントベクトルを追加する

続いて、頂点データにタンジェントベクトルを追加していきます。`Mesh.h`を開き、`Vertex`構造体にの定義タンジェントベクトルのメンバ変数を追加してください。

```diff
 struct Vertex
 {
   vec3 position; // 頂点座標
   vec2 texcoord; // テクスチャ座標
   vec3 normal;   // 法線ベクトル
+  vec4 tangent;  // 接線ベクトル
 };

 /**
 * 描画パラメータ
```

同様に、`SkeletalVertex`構造体にもタンジェントベクトルを追加します。`SkeletalVertex`構造体の定義にタンジェントベクトルのメンバ変数を追加してください。

```diff
 struct SkeletalVertex
 {
   vec3 position; // 頂点座標
   vec2 texcoord; // テクスチャ座標
   vec3 normal;   // 法線ベクトル
+  vec4 tangent;  // 接線ベクトル
   uint16_t joints[4]; // 影響を受ける関節の番号
   uint16_t weights[4];  // 各関節の影響度
```

次に、頂点アトリビュートにタンジェントベクトルを追加します。`Mesh.cpp`を開き、`MeshBuffer`コンストラクタの定義に次のプログラムを追加してください。

```diff
   // 頂点アトリビュートを設定
   vao->SetAttribute(0, 3, sizeof(Vertex), offsetof(Vertex, position));
   vao->SetAttribute(1, 2, sizeof(Vertex), offsetof(Vertex, texcoord));
   vao->SetAttribute(2, 3, sizeof(Vertex), offsetof(Vertex, normal));
+  vao->SetAttribute(3, 4, sizeof(Vertex), offsetof(Vertex, tangent));

   vaoSkeletal = VertexArrayObject::Create();
   glBindVertexArray(*vaoSkeletal);
   glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, *buffer);
   glBindBuffer(GL_ARRAY_BUFFER, *buffer);
   vaoSkeletal->SetAttribute(0, 3, sizeof(SkeletalVertex),
     offsetof(SkeletalVertex, position));
   vaoSkeletal->SetAttribute(1, 2, sizeof(SkeletalVertex),
     offsetof(SkeletalVertex, texcoord));
   vaoSkeletal->SetAttribute(2, 3, sizeof(SkeletalVertex),
     offsetof(SkeletalVertex, normal));
+  vaoSkeletal->SetAttribute(3, 4, sizeof(SkeletalVertex),
+    offsetof(SkeletalVertex, tangent));
-  glEnableVertexAttribArray(3);
-  glVertexAttribIPointer(3, 4, GL_UNSIGNED_SHORT, sizeof(SkeletalVertex),
+  glEnableVertexAttribArray(4);
+  glVertexAttribIPointer(4, 4, GL_UNSIGNED_SHORT, sizeof(SkeletalVertex),
     reinterpret_cast<void*>(offsetof(SkeletalVertex, joints)));
-  glEnableVertexAttribArray(4);
-  glVertexAttribPointer(4, 4, GL_UNSIGNED_SHORT, GL_TRUE, sizeof(SkeletalVertex),
+  glEnableVertexAttribArray(5);
+  glVertexAttribPointer(5, 4, GL_UNSIGNED_SHORT, GL_TRUE, sizeof(SkeletalVertex),
     reinterpret_cast<void*>(offsetof(SkeletalVertex, weights)));
```

それから、スケルタルメッシュ用の`LoadOBJ`メンバ関数において、`Vertex`構造体の値を`SkeletalVertex`構造体にコピーしています。ここにも、タンジェントベクトルをコピーするプログラムを追加しなくてはなりません。

スケルタルメッシュ用の`LoadOBJ`メンバ関数の定義に、次のプログラムを追加してください。

```diff
   for (int i = 0; i < meshData.vertices.size(); ++i) {
     skeletalVertices[i].position = meshData.vertices[i].position;
     skeletalVertices[i].texcoord = meshData.vertices[i].texcoord;
     skeletalVertices[i].normal = meshData.vertices[i].normal;
+    skeletalVertices[i].tangent = meshData.vertices[i].tangent;
   }
```

これで、タンジェントベクトルが頂点シェーダに送られるようになりました。

### 2.10 タンジェントベクトルを計算する

タンジェント空間の座標系はポリゴンごとに定義されます。なぜなら、ポリゴンの法線と、ポリゴンに貼り付けられるテクスチャの向きは、ポリゴンごとに異なっているからです。

このことは、頂点が複数のポリゴンで共有されている場合に問題となります。一般に、「ひとつの頂点に設定できるタンジェント空間はひとつだけ」だからです。

そのため、法線テクスチャ作成ツールは「頂点が関わる全てのタンジェント空間を平均化」する処理を行います。そして、平均化されたタンジェント空間を使って法線テクスチャを作成します。

しかし、タンジェント空間の平均化には次のような問題があります。

>* 浮動小数点数の計算誤差
>* 平均化手順が公開されていないツールがある

浮動小数点数の計算誤差により、タンジェント空間を計算するとき、同じポリゴンでもインデックス順が異なるとわずかに異なる結果になります。同様に、タンジェント空間を加算する順序が異なる場合も結果が変わります。

また、ツールの平均化手順が公開されていない場合、ツールと同じタンジェント空間を計算することはほとんど不可能です。

これらの問題があるため、ツールが異なるとタンジェント空間を正しく復元できません。結果として、ポリゴンの境界で不自然な陰影が生まれることがありました。

この問題をなくす方法のひとつは、同じモデリングツールを使って3Dモデルと法線テクスチャを作成することです。しかし近年は、3Dモデルに求められる水準が上がり、ひとつのツールですべての作業を行うことが困難になってきました。

複数のツールで作業を行うには、標準的なタンジェント空間計算方法が必要です。そんなときに登場したのが`MikkTSpace`(ミック・ティー・スペース)という方法です。

`MikkTSpace`は、2008年にMorten S. Mikkelsen氏が発表した「標準的なタンジェント空間の計算方法」です。

`MikkTSpace`の特徴は、「同じ3Dモデルであれば、たとえインデックス順が異なっていても常に同じ計算結果が得られる」ことです。入力データの順序に注意する必要がないため、ため、多くの3Dツールやゲームエンジンで採用されています。

それ以外の基本的な部分は「タンジェントとバイタンジェントのなす角が大きいほど、その頂点に影響する面積が広い」という考え方にもとづいています。

>2008年の論文は、コペンハーゲン大学のサイト(以下のURL)からダウンロードできます。<br>
>`http://image.diku.dk/projects/media/morten.mikkelsen.08.pdf`
>
>また、以下のURLでは法線とタンジェントの計算方法について、いくつかの議論を読むことができます。<br>
>`https://github.com/KhronosGroup/glTF/issues/2056`

### 2.11 プロジェクトにMikkTSpaceを組み込む

`MikkTSpace`は、`https://github.com/mmikk/MikkTSpace`で公開されているソースファイルを組み込んで利用します。環境にかかわらず同じ結果を得られることが重要なので、自分で実装することは避けてください。

それでは、ソースファイルをダウンロードしてプロジェクトに組み込みましょう。ブラウザで
`https://github.com/mmikk/MikkTSpace`を開いてください。すると次のようなページが表示されます。

<p align="center">
<img src="images/22_mikktspace_0.png" width="60%" />
</p>

`Code`(コード)と書かれた緑色のボタンをクリックすると、サブメニューが表示されます。<br>
一番下の`Download ZIP`(ダウンロード・ジップ)をクリックして、適当なフォルダにZIPファイルをダウンロードしてください。

次に、プロジェクトの`Src`フォルダに、`MikkTSpace`という名前のフォルダを作成してください。

<p align="center">
<img src="images/22_mikktspace_1.png" width="50%" />
</p>

ダウンロードしたZIPファイルを展開すると`mikktspace.h`と`mikktspace.c`というファイルが見つかります。この2つのファイルを、先ほど作成した`MikkTSpace`フォルダにコピーしてください。

次に、プロジェクトにMikkTSpace用のフィルターを追加します。Visual Studioでプロジェクトを開いてください。そして、ソリューションエクスプローラーにある「ソースファイル」フィルタを右クリックして右クリックメニューを開いてください(①)。

右クリックメニューから「追加」を選び(②)、次に「新しいフィルター(F)」を選択してください(③)。ソリューションエクスプローラーに「新しいフィルター」が追加されるので、名前を`MikkTSpace`に変更してください。

<p align="center">
<img src="images/22_mikktspace_2.png" width="50%" />
</p>

作成したフィルタに、MikkTSpace用のファイルを追加します。エクスプローラーでプロジェクトの`Src`フォルダを開いてください。次に、エクスプローラーの`MikkTSpace`フォルダをVisual Studioの`MikkTSpace`フィルタにドラッグ&ドロップしてください。

<p align="center">
<img src="images/22_mikktspace_3.png" width="66%" />
</p>

ドラッグ&ドロップを使うと、フォルダ内にあるすべてのファイルをプロジェクトに追加することができます。

この段階でプロジェクトをビルドして、エラーが起きないことを確認してください。

### 2.12 MikkTSpace用のクラスを定義する

`mikktspace.h`には`SMikkTSpaceInterface`(エス・ミック・ティー・スペース・インターフェイス)と`SMikkTSpaceContext`(エス・ミック・ティー・スペース・コンテキスト)という2つの構造体が定義されています。

>* `SMikkTSpaceInterface`構造体: MikkTSpaceシステムとのあいだで、3Dモデルデータを送受信するための関数ポインタを設定する。
>* `SMikkTSpaceContext`構造体: MikkTSpaceシステムを実行する、`genTangSpaceDefault`(ジェン・タン・スペース・デフォルト)関数の引数。`SMikkTSpaceInterface`構造体へのポインタと、ユーザーデータ(プログラムが任意に設定できるデータ)を設定する。

とりあえずヘッダファイルをインクルードしましょう。<br>
`Mesh.cpp`を開き、`mikktspace.h`をインクルードしてください。

```diff
 #include "Mesh.h"
 #include "ProgramObject.h"
 #include "Debug.h"
+#include "MikkTSpace/mikktspace.h"
 #include <numeric>
 #include <algorithm>
```

次に、`MikkTSpace`クラスを定義します。これは`SMikkTSpaceInterface`を実装するクラスです。インクルード文の下に、次のプログラムを追加してください。

```diff
 #include <filesystem>
 #include <fstream>
 #include <stdio.h>
+
+/**
+* MikkTSpaceのインターフェイス実装
+*/
+class MikkTSpace
+{
+public:
+  // コンストラクタ
+  MikkTSpace()
+  {
+  }
+
+  // デストラクタ
+  ~MikkTSpace() = default;
+
+  // メンバ変数
+  SMikkTSpaceInterface interface;
+};

 /**
 * プリミティブを描画する
```

>**【interfaceメンバ変数が青く表示されるんですけど？】**<br>
>これは、`interface`がC++/CLI(シープラスプラス・シーエルアイ)という言語のキーワードだからです。C++/CLIはMicrosoftが開発した「C++に.NET対応機能を組み込んだ言語」です。名前にC++と付いてはいますが、C++とは別モノです。<br>
>しかし、IntelliSenseはC++とC++/CLIを区別しません。そのため、C++/CLI専用のキーワードにも色が付いてしまいます。<br>
>2022年現在、残念ながらこの現象を回避する方法はありません。

`SMikkTSpaceInterface`に設定するすべての関数ポインタ型は「コールバック関数(ライブラリが必要なタイミングで呼び出す関数のこと)」です。これらのコールバック関数は
`SMikkTSpaceContext`型のポインタ引数を持ちます。

`SmikkTSpaceContext`型には`SMikkTSpaceInterface`へのポインタに加えて、ユーザー(ライブラリの利用者)が自由に指定できる`m_pUserData`(エム・ピー・ユーザーデータ)メンバ変数が用意されています。

コールバック関数はこのメンバ変数を通じて必要なデータにアクセスします。最低限必要なのは3Dモデルの頂点データとインデックスデータです。

しかし、指定できるポインタはひとつだけです。そこで、この2つを持つ構造体を作成して、構造体のポインタを指定することにします。`MikkTSpace`クラスの定義に、次の型定義を追加してください。

```diff
 class MikkTSpace
 {
 public:
+  /**
+  * MikkTSpace用のユーザーデータ
+  */
+  struct UserData
+  {
+    std::vector<uint16_t>& indices;
+    std::vector<Vertex>& vertices;
+  };
+
   // コンストラクタ
   MikkTSpace()
```

### 2.13 総ポリゴン数を返す関数を設定する

MikkTSpaceを動作させるには、以下の6つのインターフェイス関数を設定する必要があります。

>* m_getNumFaces: 3Dモデルのポリゴン数を返す。
>* m_getNumVerticesOfFace: ひとつのポリゴンの頂点数を返す。
>* m_getPosition: 頂点の座標を返す。
>* m_getNormal: 頂点の法線を返す。
>* m_getTexCoord: 頂点のテクスチャ座標を返す。
>* m_setTSpaceBasic: タンジェント空間の情報を受け取る。

>上記以外に`m_setTSpace`というインターフェイス関数があります。この関数を使うと、
>`m_setTSpaceBasic`より詳細なタンジェント空間情報を受け取れます。通常の法線マッピングでは詳細情報を使わないので、今回は設定しません。

それでは、インターフェイス関数を作成しましょう。それぞれの関数は比較的単純なので、ラムダ式で無名関数を作成して割り当てることにします。

`MikkTSpace`クラスのコンストラクタに次のプログラムを追加してください。

```diff
   // コンストラクタ
   MikkTSpace()
   {
+    // モデルの総ポリゴン数を返す
+    interface.m_getNumFaces = [](const SMikkTSpaceContext* pContext)
+    {
+      UserData* p = static_cast<UserData*>(pContext->m_pUserData);
+      return static_cast<int>(p->indices.size() / 3);
+    };
   }

   // デストラクタ
```

`m_getNumFaces`(エム・ゲット・ナム・フェイシズ)には「モデルの総ポリゴン数を返す」関数を設定します。

ユーザーデータは`SMikkTSpaceContext`構造体の`m_pUserData`(エム・ピー・ユーザーデータ)メンバ変数として渡されます。この変数は`void*`型なので、`static_cast`を使って
`UserData`型に戻してから使用します。

総ポリゴン数はインデックス数の1/3です。

### 2.14 ポリゴンの頂点数を返す関数を設定する

次に、ポリゴンの頂点数を返す関数`m_getNumVerteciesOfFace`(エム・ゲット・ナム・バーティシーズ・オフ・フェイス)メンバ変数を設定します。`m_getNumFaces`メンバ変数を設定するプログラムの下に、次のプログラムを追加してください。

```diff
       UserData* p = static_cast<UserData*>(pContext->m_pUserData);
       return static_cast<int>(p->indices.size() / 3);
     };
+
+    // ポリゴンの頂点数を返す
+    interface.m_getNumVerticesOfFace = [](const SMikkTSpaceContext* pContext,
+      int iFace)
+    {
+      return 3;
+    };
   }

   // デストラクタ
```

MikkTSpaceは三角形だけでなく四角形にも対応しています。そのため、ポリゴンごとに頂点数を指定できるようになっています。今回は三角形しか使わないため、常に3を返します。

### 2.15 頂点の座標を返す関数を設定する

続いて、頂点の座標を返す`m_getPosition`(エム・ゲット・ポジション)メンバ変数を設定します。`m_getNumVerticesOfFace`メンバ変数を設定するプログラムの下に、次のプログラムを追加してください。

```diff
     {
       return 3;
     };
+
+    // 頂点の座標を返す
+    interface.m_getPosition = [](const SMikkTSpaceContext* pContext,
+      float fvPosOut[], int iFace, int iVert)
+    {
+      UserData* p = static_cast<UserData*>(pContext->m_pUserData);
+      const int index = p->indices[iFace * 3 + iVert];
+      std::copy_n(&p->vertices[index].position.x, 3, fvPosOut);
+    };
   }

   // デストラクタ
```

このインターフェイス関数には、`pContext`(ピー・コンテキスト)以外に`fvPosOut`(エフブイ・ポス・アウト)と`iFace`(アイ・フェイス)、`iVert`(アイ・バート)という3つの引数があります。

実装する内容は、

>`iFace`番目のポリゴンの`iVert`番目の頂点の座標を、`fvPosOut`配列にX,Y,Zの順に代入すること。

です。`iVert`には0～2の値が指定される点に注意してください。

### 2.16 頂点の法線を返す関数を設定する

頂点の法線を返す`m_getNormal`(エム・ゲット・ノーマル)メンバ変数を設定します。
`m_getPosition`メンバ変数を定義するプログラムの下に、次のプログラムを追加してください。

```diff
       const int index = p->indices[iFace * 3 + iVert];
       std::copy_n(&p->vertices[index].position.x, 3, fvPosOut);
     };
+
+    // 頂点の法線を返す
+    interface.m_getNormal = [](const SMikkTSpaceContext* pContext,
+      float fvNormOut[], int iFace, int iVert)
+    {
+      UserData* p = static_cast<UserData*>(pContext->m_pUserData);
+      const int index = p->indices[iFace * 3 + iVert];
+      std::copy_n(&p->vertices[index].normal.x, 3, fvNormOut);
+    };
   }

   // デストラクタ
```

関数の内容は`m_getPosition`とほとんど同じです。違いは、引数`fvNormalOut`(エフブイ・ノーマル・アウト)配列に法線を代入することだけです。

### 2.17 頂点のテクスチャ座標を返す関数を設定する

頂点のテクスチャ座標を返す`m_geteTexCoord`(エム・ゲット・テックスコード)メンバ変数を設定します。

`m_getNormal`メンバ変数を設定するプログラムの下に、次のプログラムを追加してください。

```diff
       const int index = p->indices[iFace * 3 + iVert];
       std::copy_n(&p->vertices[index].normal.x, 3, fvNormOut);
     };
+
+    // 頂点のテクスチャ座標を返す
+    interface.m_getTexCoord = [](const SMikkTSpaceContext* pContext,
+      float fvTexcOut[], int iFace, int iVert)
+    {
+      UserData* p = static_cast<UserData*>(pContext->m_pUserData);
+      const int index = p->indices[iFace * 3 + iVert];
+      std::copy_n(&p->vertices[index].texcoord.x, 2, fvTexcOut);
+    };
   }

   // デストラクタ
```

この関数も`m_getPosition`, `m_getNormal`とほとんど同じです。ただし、テクスチャ座標は二次元なので、`fvTexOut`(エフブイ・テックス・アウト)配列も2要素しかない点には注意してください。

### 2.18 タンジェント空間データを受け取る関数を設定する

続いて、`m_setTSpaceBasic`(エム・セット・ティースペース・ペーシック)メンバ変数を設定します。`m_getTexCoord`メンバ変数を設定するプログラムの下に、次のプログラムを追加してください。

```diff
       const int index = p->indices[iFace * 3 + iVert];
       std::copy_n(&p->vertices[index].texcoord.x, 2, fvTexcOut);
     };
+
+    // 「タンジェントベクトル」と「バイタンジェントベクトルの向き」を受け取る
+    interface.m_setTSpaceBasic = [](const SMikkTSpaceContext* pContext,
+      const float fvTangent[], float fSign, int iFace, int iVert)
+    {
+      UserData* p = static_cast<UserData*>(pContext->m_pUserData);
+      const int index = p->indices[iFace * 3 + iVert];
+      p->vertices[index].tangent =
+        vec4(fvTangent[0], fvTangent[1], fvTangent[2], fSign);
+    };
   }

   // デストラクタ
```

このインターフェイスはMikkTSpaceが計算した「タンジェント空間のデータ」を受け取るためのものです。引数の意味は次のとおりです。

>* `fvTangent`(エフブイ・タンジェント): タンジェントベクトル
>* `fSign`(エフ・サイン): バイタンジェントベクトルの向き
>* `iFace`(アイ・フェイス): データを設定するポリゴンの番号
>* `iVert`(アイ・バート): データを設定する頂点の番号

### 2.19 使わないメンバ変数にnullptrを設定する

MikkTSpaceには、タンジェント空間を受け取る関数が２つあります。ひとつはすぐ前に設定した`m_setTSpaceBasic`で、もうひとつは`m_setTSpace`メンバ変数です。

`m_setTSpace`を設定すると、「レリーフマッピング」という技法のための「より詳細なデータ」を受け取ることができます。しかし、法線マッピングでは必要ありません。

MikkTSpaceでは、`m_setTSpaceBasice`または`m_setTSpace`のうち、使わないメンバ変数にはnullptrを設定しておく必要があります。`m_setTSpaceBasic`メンバ変数を設定するプログラムの下に、次のプログラムを追加してください。

```diff
       p->vertices[index].tangent =
         vec4(fvTangent[0], fvTangent[1], fvTangent[2], fSign);
     };
+
+    // 使わないのでnullptrを設定
+    interface.m_setTSpace = nullptr;
   }

   // デストラクタ
```

これでインターフェイスの設定は完了です。

### 2.20 MikkTSpaceオブジェクトを作成する

さて、完成したMikkTSpaceクラスですが、適当なタイミングでオブジェクトを作成しなくてはなりません。MikkTSpaceオブジェクトを作成するタイミングには、次の2パターンが考えられます。

>* 最初に作成して使い回す。
>* OBJファイルを読み込むときに毎回作成する。

選択基準となるのは「オブジェクトのサイズ」、「作成にかかる時間」です。

| | メリット | デメリット |
|:-:|:--|:--|
| 使い回す | 作成にかかる時間が最初の1回だけ | サイズが大きいとメモリが無駄になる |
| 毎回作成 | メモリが無駄にならない | 読み込み時間が長くなる |

MikkTSpaceクラスの場合、サイズは大きくありません。コンストラクタも、そんなに時間のかかる内容ではありません。つまり、MikkTSpaceのような小さなクラスは「どちらでも大差ない」のです。

このような小さなクラスの作成タイミングは、実行する環境によって決めることが多いです。そして、2023年現在のコンピューターにとっては、どちらかというとメモリより実行速度のほうが重要です。

そこで、「最初に作成して使い回す」ことにします。

ということで、MikkTSpaceクラスは`MeshBuffer`コンストラクタで作成することにします。<br>
また、使い回すためにはメンバ変数にする必要があります。`Mesh.h`を開き、`MeshBuffer`クラスの定義に次のプログラムを追加してください。

```diff
   BufferObjectPtr buffer;   // 頂点データおよびインデックスデータ
   size_t usedBytes = 0;     // バッファの使用済み容量(バイト)
   TextureCallback textureCallback; // テクスチャ作成コールバック
+  std::shared_ptr<class MikkTSpace> mikkTSpace;
 };

 /**
 * 欠けている法線を補う
```

`class MikkTSpace`のように指定すると、先行宣言がなくても型を指定できます。続いて`Mesh.cpp`を開き、`MeshBuffer`コンストラクタの末尾に次のプログラムを追加してください。

```diff
   // 描画パラメータの容量を予約
   drawParamsList.reserve(100);
+
+  // タンジェント空間計算用のオブジェクトを作成する
+  mikkTSpace = std::make_shared<MikkTSpace>();
+  if (!mikkTSpace) {
+    LOG_ERROR("MikkTSpaceの作成に失敗");
+  }
 }

 /**
 * OBJファイルを読み込む
```

### 2.21 MikkTSpaceを使ってタンジェントを計算する

最後に、MikkTSpaceオブジェクトを使ってタンジェント空間を計算するプログラムを追加しましょう。`LoadOBJ`メンバ関数に次のプログラムを追加してください。

```diff
   // 設定されていない法線を補う
   FillMissingNormals(vertices.data(), vertices.size(),
     indices.data(), indices.size());
+
+  // タンジェントベクトルを計算
+  if (mikkTSpace) {
+    // MikkTSpaceライブラリでタンジェントを計算
+    MikkTSpace::UserData userData = { indices, vertices };
+    SMikkTSpaceContext context = { &mikkTSpace->interface, &userData };
+    genTangSpaceDefault(&context);
+  }

   // データの位置を初期化
   const void* indexOffset = 0;
   const GLint baseVertex = 0;
```

それから、OBJファイルから読み取った法線ベクトルは正規化されていない場合があります。正しいタンジェントベクトルを計算するには、MikkTSpaceに渡す前に法線ベクトルを正規化しておく必要があります。

`CreateMeshDataFromOBJ`メンバ関数の定義に次のプログラムを追加してください。

```diff
     // 法線の読み取りを試みる
     vec3 vn;
     if (sscanf(p, " vn %f %f %f", &vn.x, &vn.y, &vn.z) == 3) {
+      vn = normalize(vn); // 正規化されていないことがあるので正規化する
       normals.push_back(vn);
       continue;
     }
```

プログラムが書けたらビルドして実行してください。`a_piece_of_nature`アセットの岩と針葉樹には法線テクスチャが設定されているので、法線マッピングの効果がすぐに確認できます。

樹木の葉の一枚一枚に凹凸が付き、岩の割れ目がただの絵ではなく実際に凹んでいるように見えていたら成功です。

<p align="center">
<img src="images/22_result_1.jpg" width="45%" />
</p>

>**【タンジェント空間は実行時に計算しなくてもよい】**<br>
>市販ゲームなどでは、タンジェント空間の計算はデータ作成時に行います。事前に作成しておくことで、データのロード時間を短縮できます。ただし、タンジェントを扱えるファイル形式を使わなくてはなりません(FBX, Collada, glTFなど)。ただし、汎用ファイル形式には無駄なデータが大量に含まれるため、ゲーム専用のファイル形式を開発して使うことがほとんどです。<br>
>なお、ファイルやデータの設計はOpenGLの<ruby>範疇<rt>はんちゅう</rt></ruby>ではないため、本テキストでは扱いません。とはいえ、ロード時間を短縮するためのデータ設計を考えたり、実際に試してみるのはよい練習になります。余裕があればチャレンジしてみてください。

>**【2章のまとめ】**
>
>* 
>* 
>* 
>* 
>* 
